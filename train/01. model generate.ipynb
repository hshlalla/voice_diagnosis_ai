{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 환경설정 \n",
    "환경설정을 잘못할경우 잘안되는경우가 많으니 꼭 확인할 것\n",
    "실험후 버전 업데이트 하게 될경우 api에서 test할때 디펜던시 오류나는지 꼭 체크해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4126,
     "status": "ok",
     "timestamp": 1648514737482,
     "user": {
      "displayName": "Suhun Hong",
      "userId": "13401582083434995650"
     },
     "user_tz": -540
    },
    "id": "FYLF3f00n44F"
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------*  tool\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#------------------------------------------------*  tensor, keras model\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.layers import Dropout, GlobalAveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "#------------------------------------------------* sklearn, score, metrics\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "#------------------------------------------------*  warnings filter\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "#--------------------\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration\n",
    "- 다른실험할때는 Class_name을 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"/104data/dataset/음성/voice_to_image/dataset20250127/\"\n",
    "# for문으로 처리하려고 했으나 각 진단마다 에폭이나 learning rate를 바꿔야 하는일들이 있어서 4개 타입 바꿔가면서 4번 돌릴것.\n",
    "CLASS_NAME=\"normal_abnormal\" #MCI_AD, SCI_AD, SCI_MCI,normal_abnormal\n",
    "private_dir = f\"{DATASET_PATH}{CLASS_NAME}/\"\n",
    "# 위 폴더는 개인환경에 맞추어 수정하시면 됩니다\n",
    "\n",
    "os.makedirs(\"./models\",exist_ok=True)\n",
    "os.makedirs(\"./images\",exist_ok=True)\n",
    "\n",
    "BASE_SAVE_PATH = f\"./models/{CLASS_NAME}/\"\n",
    "#pretrained 모델을 사용할때는 이미지 사이즈가 224,224가 맞습니다.\n",
    "#300*300으로 해도 잘 나와서 추후 수정하지 않고 유지 하였으나 224,224로 사용하시는것이 일반적인방법입니다.\n",
    "IMG_SIZE = (300, 300)\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# 10번 이하는 쏠림이 있는 모델이 생성되는 경우가 많음. \n",
    "EPOCHS = 1\n",
    "# 학습이 안되는경우 learning rate를 조정하시는게 가장 효과적인 방법입니다.\n",
    "\n",
    "LEARNING_RATE = 1.0e-6\n",
    "SEED = 14\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixed seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed를 고정. 일정한 값 도출 및 추가되는 다른 것들에 대한 효과를 보기위해서 고정한다.\n",
    "# 랜덤시드 제대로 고정됐는지 실험 완료\n",
    "# 재현성을 위해 시드를 고정하지만 아래 3개 환경은 성능이 떨어지는 이슈가 있어서 고정했음\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    random.seed(seed)\n",
    "    # os.environ['TF_DETERMINISTIC_OPS'] = \"1\"\n",
    "    # os.environ['TF_CUDNN_DETERMINISM'] = \"1\"\n",
    "    # os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1648514840105,
     "user": {
      "displayName": "Suhun Hong",
      "userId": "13401582083434995650"
     },
     "user_tz": -540
    },
    "id": "SjBvE6bDqsV5"
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------* \n",
    "# AUC chart 옵션설정\n",
    "def plot_roc(pred,y, foldnum):\n",
    "    fpr, tpr, _ = roc_curve(y, pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(f'./images/{CLASS_NAME}/AUC'+str(foldnum)+'.png')\n",
    "    plt.show()\n",
    "\n",
    "def plot_metrics(history, foldnum):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'./images/{CLASS_NAME}/accuracy_fold{foldnum}.png')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'./images/{CLASS_NAME}/loss_fold{foldnum}.png')\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(labels, predictions, foldnum):\n",
    "    cm = confusion_matrix(labels, predictions)\n",
    "    f, ax = plt.subplots(figsize=(4, 4))\n",
    "    sns.heatmap(cm, annot=True, linewidths=0.01, cmap=\"Greens\", linecolor=\"gray\", fmt='.1f', ax=ax)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.savefig(f'./images/{CLASS_NAME}/confusion_matrix_fold{foldnum}.png')\n",
    "    plt.show()\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1648514840105,
     "user": {
      "displayName": "Suhun Hong",
      "userId": "13401582083434995650"
     },
     "user_tz": -540
    },
    "id": "G34d4lIrqsTb"
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------* \n",
    "# Call back 옵션설정\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_accuracy', factor=0.90, patience=3, verbose=0, mode='auto', min_lr=1e-7)\n",
    "checkpoint = ModelCheckpoint(f'{BASE_SAVE_PATH}/best.h5', monitor= 'val_accuracy', mode= 'max', save_best_only = True, verbose= 0)\n",
    "# early_stopping의 경우 30번 이하일 경우 모델성능이 매우 떨어지기 때문에 30 이상 결과를 위해해서 30으로 걸어둠.\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=30, mode='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 가중치 조절\n",
    "- 불균형데이터로 실험할경우 사용하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 수\n",
    "num_abnormal = 286\n",
    "num_normal = 566\n",
    "num_total = num_abnormal + num_normal\n",
    "\n",
    "weight_normal = (1 / num_abnormal) * (num_total)/2.0\n",
    "weight_abnormal = (1 / num_normal)  * (num_total)/2.0 \n",
    "\n",
    "# 각 클래스의 가중치 계산\n",
    "class_weights = {\n",
    "    0: weight_abnormal,  # class 0 (abnormal)\n",
    "    1: weight_normal   # class 1 (normal)\n",
    "}\n",
    "\n",
    "# 정규화를 위해 전체 가중치의 합으로 나눔\n",
    "total = sum(class_weights.values())\n",
    "class_weights = {k: v / total for k, v in class_weights.items()}\n",
    "\n",
    "# 클래스 가중치 출력\n",
    "print(\"Class weights: \", class_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vgg16_model():\n",
    "    # 기본적으로 pretrained 모델은 224,224 를 사용합니다.\n",
    "    # 기존 만들어진 이미지가 300*300 이기 때문에 300*300을 사용했지만 224*224를 권장합니다.\n",
    "    conv_base = VGG16(include_top=False, input_shape=(300, 300, 3), weights=\"imagenet\")\n",
    "    for i, layer in enumerate(conv_base.layers):\n",
    "        layer.trainable=False\n",
    "    for layer in conv_base.layers[-20:]:\n",
    "        layer.trainable = True\n",
    "    #for i, layer in enumerate(conv_base.layers):\n",
    "        #print(i, layer.name, layer.trainable)\n",
    "\n",
    "    #-----------------------------------------------------------------------------------------------* \n",
    "    #vgg16모델 FineTunning           \n",
    "    x = conv_base.output\n",
    "    # flatten 사용시 376mb, flatten 대신 glovalAverage 사용하는것도 추천. (모델 용량이 많이 줄어듭니다.)\n",
    "    #x = Flatten()(x) # Flatten dimensions to for use in FC layers\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.4)(x) # Dropout layer to reduce overfitting\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.4)(x) # Dropout layer to reduce overfitting #선택사항        \n",
    "    x = Dense(256, activation='relu')(x) # 2단계에서 여기서 추출\n",
    "    # sigmoid와 softmax중에 softmax를 채택한 이유는 이후 모델이 커지면 sigmoid는 수렴이 잘 안되는 경우가 발생했습니다.\n",
    "    # softmax는 카테고리컬을 꼭 사용하세요 binary로 분류도 가능하지만 정확한 계산을 위해서 categorical을 사용하는것이 필수입니다.\n",
    "    x = Dense(2, activation='softmax')(x) \n",
    "    # transfer_model.summary()\n",
    "    return Model(inputs=conv_base.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1648514840106,
     "user": {
      "displayName": "Suhun Hong",
      "userId": "13401582083434995650"
     },
     "user_tz": -540
    },
    "id": "EIbmBeP5qsRE"
   },
   "outputs": [],
   "source": [
    "def train_model(train_dir, test_dir, foldnum, qnum):\n",
    "    train_datagen = ImageDataGenerator(rescale=1.0 / 255, validation_split=0.2)\n",
    "    test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # flow_from_directory의 경우 폴더만 구성되어 있으면 바로 분류 모델 생성이 가능하다. 어떤 폴더가 0 번이 되는지 label의 확인 필요\n",
    "    # 알파벳 순으로 라벨이 결정되기 때문에 ex) mci_ad 의 경우 ad가 0번 label을 가지고 mci가 1번 라벨을 가짐.\n",
    "    train_gen = train_datagen.flow_from_directory(\n",
    "        train_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, shuffle=True, seed=SEED, subset=\"training\")\n",
    "    val_gen = train_datagen.flow_from_directory(\n",
    "        train_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, shuffle=True, seed=SEED, subset=\"validation\")\n",
    "    test_gen = test_datagen.flow_from_directory(\n",
    "        test_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, shuffle=False, seed=SEED)\n",
    "\n",
    "    model = build_vgg16_model()\n",
    "    model.compile(optimizer=tf.optimizers.Nadam(learning_rate=LEARNING_RATE),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        steps_per_epoch=len(train_gen),\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=val_gen,\n",
    "        validation_steps=len(val_gen),\n",
    "        verbose=1,\n",
    "        callbacks=[lr_reduce, early_stopping,checkpoint]\n",
    "    )\n",
    "\n",
    "    val_loss = history.history['val_loss']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "    # Confusion Matrix and Metrics\n",
    "    predictions = model.predict(test_gen, steps=len(test_gen), verbose=0)\n",
    "    pred_labels = np.argmax(predictions, axis=1)\n",
    "    cm = plot_confusion_matrix(test_gen.labels, pred_labels, foldnum)\n",
    "\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    accuracy = (tn + tp) / (tn + tp + fn + fp)\n",
    "    precision = precision_score(test_gen.labels, pred_labels, average='binary')\n",
    "    recall = recall_score(test_gen.labels, pred_labels, average='binary')\n",
    "\n",
    "    # Save model\n",
    "    acc = round(accuracy * 100, 1)\n",
    "    model_save_path = f\"{BASE_SAVE_PATH}/model_{CLASS_NAME}_q{qnum}_fold{foldnum}_acc{acc}.h5\"\n",
    "    model.save(model_save_path)\n",
    "\n",
    "\n",
    "    # Plot metrics\n",
    "    plot_metrics(history, foldnum)\n",
    "    plot_roc(pred_labels,test_gen.labels, foldnum)\n",
    "    print(f\"Precision: {precision*100:.2f}%\")\n",
    "    print(f\"Recall: {recall*100:.2f}%\")\n",
    "    print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main loop\n",
    "for qnum in range(1, 12):\n",
    "    for foldnum in range(1, 6):\n",
    "        base_dir = f\"{private_dir}{qnum}/iterations\"\n",
    "        train_dir = os.path.join(base_dir, f'iteration{foldnum}/train/')\n",
    "        test_dir = os.path.join(base_dir, f'iteration{foldnum}/test/')\n",
    "\n",
    "        print(f\"Training fold {foldnum} for question {qnum}...\")\n",
    "        model=train_model(train_dir, test_dir, foldnum, qnum)\n",
    "        K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 틀린것 확인할때 아래 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "57KX00hIrVA-"
   },
   "outputs": [],
   "source": [
    "\n",
    "def visualize_wrong_predictions(model, test_generator):\n",
    "    predicted_result = model.predict(test_generator)\n",
    "    predicted_labels = np.argmax(predicted_result, axis=1)\n",
    "\n",
    "    test_labels = test_generator.labels\n",
    "\n",
    "    wrong_result = []\n",
    "\n",
    "    for n in range(0, len(test_labels)):\n",
    "        if predicted_labels[n] != test_labels[n]:\n",
    "            wrong_result.append(n)\n",
    "\n",
    "    samples = random.choices(population=wrong_result, k=16)\n",
    "\n",
    "    count = 0\n",
    "    nrows = ncols = 4\n",
    "\n",
    "    plt.figure(figsize=(12,8))\n",
    "\n",
    "    for n in samples:\n",
    "        count += 1\n",
    "        plt.subplot(nrows, ncols, count)\n",
    "        plt.imshow(test_generator[n].reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "        tmp = \"Label:\" + str(test_labels[n]) + \", Prediction:\" + str(predicted_labels[n])\n",
    "        plt.title(tmp)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOCv/KfrPTd74VHU/FZEDi0",
   "mount_file_id": "1v62ISiI6R20GpzONnrj78NQZXLkGpCHK",
   "name": "spick_처음부터 끝까지.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "python3.8.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
